{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4eeba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Collect Explore\n",
    "# Stage 2: Annotate and convert labelme annotations to seg\n",
    "# Stage 3: Find spawn location and target for reexplore (reexplore_data.json)\n",
    "# Stage 4: Run reexplore for all objects, one at a time \n",
    "# Stage 5: Run label prop\n",
    "# Stage 6: Run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9572ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from droidlet.dashboard.o3dviz import O3DViz\n",
    "# o3dviz = O3DViz(True)\n",
    "# o3dviz.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a7b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Collect Explore to $HOME/explore_data\n",
    "\n",
    "# Stage 3: Find spawn location and target for reexplore (reexplore_data.json) in a separate out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a6ffeae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_dir /home/locobotm/0512_data/reexplore_data_0512_3/4\n",
      "saving propagated frames to /home/locobotm/0512_data/reexplore_data_0512_3/4/c1pp/pred\n",
      "height 480 width 640\n",
      "uv_one_in_cam.shape (3, 307200)\n",
      "visualize_pcd shape (307200, 3)\n",
      "src_pts_in_cur_cam.shape (307200, 3)\n",
      "annot_img.shape (480, 640), src_label.shape (480, 640)\n",
      "pts_in_cur_img.shape (307200, 3)\n",
      "(480, 640) float32\n",
      "type(semantic_obs) (640, 480)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"WEBRTC_PORT\"] = \"9999\"\n",
    "\n",
    "\"\"\"\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from droidlet.lowlevel.robot_mover_utils import transform_pose\n",
    "from droidlet.shared_data_structs import RGBDepth\n",
    "from droidlet.lowlevel.hello_robot.rotation import (\n",
    "    rotation_matrix_x,\n",
    "    rotation_matrix_y,\n",
    "    rotation_matrix_z,\n",
    ")\n",
    "import cv2\n",
    "import math\n",
    "from numba import njit\n",
    "from math import ceil, floor, isnan\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "d3_40_colors_rgb: np.ndarray = np.array(\n",
    "    [\n",
    "        [31, 119, 180],\n",
    "        [174, 199, 232],\n",
    "        [255, 127, 14],\n",
    "        [255, 187, 120],\n",
    "        [44, 160, 44],\n",
    "        [152, 223, 138],\n",
    "        [214, 39, 40],\n",
    "        [255, 152, 150],\n",
    "        [148, 103, 189],\n",
    "        [197, 176, 213],\n",
    "        [140, 86, 75],\n",
    "        [196, 156, 148],\n",
    "        [227, 119, 194],\n",
    "        [247, 182, 210],\n",
    "        [127, 127, 127],\n",
    "        [199, 199, 199],\n",
    "        [188, 189, 34],\n",
    "        [219, 219, 141],\n",
    "        [23, 190, 207],\n",
    "        [158, 218, 229],\n",
    "        [57, 59, 121],\n",
    "        [82, 84, 163],\n",
    "        [107, 110, 207],\n",
    "        [156, 158, 222],\n",
    "        [99, 121, 57],\n",
    "        [140, 162, 82],\n",
    "        [181, 207, 107],\n",
    "        [206, 219, 156],\n",
    "        [140, 109, 49],\n",
    "        [189, 158, 57],\n",
    "        [231, 186, 82],\n",
    "        [231, 203, 148],\n",
    "        [132, 60, 57],\n",
    "        [173, 73, 74],\n",
    "        [214, 97, 107],\n",
    "        [231, 150, 156],\n",
    "        [123, 65, 115],\n",
    "        [165, 81, 148],\n",
    "        [206, 109, 189],\n",
    "        [222, 158, 214],\n",
    "    ],\n",
    "    dtype=np.uint8,\n",
    ") \n",
    "\n",
    "# Values for locobot in habitat. \n",
    "# TODO: generalize this for all robots\n",
    "fx, fy = 256, 256\n",
    "cx, cy = 256, 256\n",
    "\n",
    "#locoboot\n",
    "# intrinsic_mat = np.array([[  fx, 0., cx],\n",
    "#                             [  0., fy, cy],\n",
    "#                             [  0., 0., 1.]])\n",
    "\n",
    "intrinsic_mat = np.array(\n",
    "    [[604.50262451,   0.        , 312.43200684],\n",
    "       [  0.        , 604.22351074, 236.35299683],\n",
    "       [  0.        ,   0.        ,   1.        ]]\n",
    ")\n",
    "\n",
    "# fx, fy = 605.2880249, 605.65637207\n",
    "# cx, cy = 319.11114502, 239.48382568\n",
    "# intrinsic_mat = np.array([[  fx, 0., cx],\n",
    "#                             [  0., fy, cy],\n",
    "#                             [  0., 0., 1.]])\n",
    "\n",
    "# rotation from pyrobot to canonical coordinates (https://github.com/facebookresearch/fairo/blob/main/agents/locobot/coordinates.MD)\n",
    "# rot = np.array([[0.0, 0.0, 1.0], [-1.0, 0.0, 0.0], [0.0, -1.0, 0.0]])\n",
    "# CAMERA_HEIGHT = 0.6\n",
    "# trans = np.array([0, 0, CAMERA_HEIGHT])\n",
    "\n",
    "# my hello\n",
    "# trans = np.array([ 0.03492126, -0.01123962,  1.24354383])\n",
    "\n",
    "# rot = np.array([[ 0.84003093,  0.53898409, -0.06200145],\n",
    "#  [-0.04361892, -0.04681613, -0.99795072],\n",
    "#  [-0.54078223,  0.84101391, -0.01581709]])\n",
    "\n",
    "# soumith\n",
    "trans = np.array([0.02283596, 0.01864796, 1.25382417])\n",
    "rot = np.array([\n",
    "    [0.86391456, 0.49976488, 0.06234341],\n",
    "    [0.05324502, 0.03236112, -0.99805373],\n",
    "    [-0.50081594, 0.86555262, 0.00143363]\n",
    "])\n",
    "\n",
    "\n",
    " # TODO: Consolidate camera intrinsics and their associated utils across locobot and habitat.\n",
    "def compute_uvone(height, width):\n",
    "    intrinsic_mat_inv = np.linalg.inv(intrinsic_mat)\n",
    "    img_resolution = (height, width)\n",
    "    img_pixs = np.mgrid[0 : img_resolution[0] : 1, 0 : img_resolution[1] : 1]\n",
    "    img_pixs = img_pixs.reshape(2, -1)\n",
    "    img_pixs[[0, 1], :] = img_pixs[[1, 0], :]\n",
    "    uv_one = np.concatenate((img_pixs, np.ones((1, img_pixs.shape[1]))))\n",
    "    uv_one_in_cam = np.dot(intrinsic_mat_inv, uv_one)\n",
    "    return uv_one_in_cam, intrinsic_mat, rot, trans\n",
    "\n",
    "# def compute_uvone(intrinsic_mat, height, width):\n",
    "#     intrinsic_mat_inv = np.linalg.inv(intrinsic_mat)\n",
    "#     img_pixs = np.mgrid[0:height:1, 0:width:1]\n",
    "#     img_pixs = img_pixs.reshape(2, -1)\n",
    "#     img_pixs[[0, 1], :] = img_pixs[[1, 0], :]\n",
    "#     uv_one = np.concatenate((img_pixs, np.ones((1, img_pixs.shape[1]))))\n",
    "#     uv_one_in_cam = np.dot(intrinsic_mat_inv, uv_one)\n",
    "#     return uv_one_in_cam\n",
    "\n",
    "def uncompute_pcd(pts, rot_cam, trans_cam, base_state, intrinsic_mat):\n",
    "    translation_vector = np.array(\n",
    "        [trans_cam[0] + base_state[0], trans_cam[1] + base_state[1], trans_cam[2] + 0]\n",
    "    ).reshape(-1)\n",
    "    h, w = pts.shape[0], pts.shape[1]\n",
    "\n",
    "    pts = pts - translation_vector\n",
    "\n",
    "    roty90, rotxn90 = rotation_matrix_y(90), rotation_matrix_x(-90)\n",
    "    rot_base = rotation_matrix_z(math.degrees(base_state[2]))\n",
    "\n",
    "    rotation_matrix = rot_base @ rot_cam @ rotxn90 @ roty90\n",
    "    pts = np.dot(pts, np.linalg.inv(rotation_matrix).T)\n",
    "\n",
    "    #################################################################\n",
    "    pts = np.matmul(intrinsic_mat, pts.reshape(-1, 3).T).T\n",
    "    pts[:, 0:2] /= pts[:, [2]]\n",
    "    pts = pts.reshape(h*w, 3)\n",
    "    return pts\n",
    "\n",
    "\n",
    "def compute_pcd(rgb, depth, rot_cam, trans_cam, base_state, uv_one_in_cam):\n",
    "        rgb = np.asarray(rgb).astype(np.uint8)\n",
    "        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        depth = depth.astype(np.float32)\n",
    "\n",
    "        # the realsense pointcloud seems to produce some spurious points\n",
    "        # really far away. So, limit the depth to 8 metres\n",
    "        thres = 8000\n",
    "        depth[depth > thres] = thres\n",
    "\n",
    "        depth_copy = np.copy(depth)\n",
    "\n",
    "        depth = depth.reshape(rgb.shape[0] * rgb.shape[1])\n",
    "\n",
    "        # normalize by the camera's intrinsic matrix\n",
    "        pts_in_cam = np.multiply(uv_one_in_cam, depth)\n",
    "        pts = pts_in_cam.T\n",
    "\n",
    "        # Now, the points are in camera frame.\n",
    "        # In camera frame\n",
    "        # z is positive into the camera\n",
    "        # (larger the z, more into the camera)\n",
    "        # x is positive to the right\n",
    "        # (larger the x, more right of the origin)\n",
    "        # y is positive to the bottom\n",
    "        # (larger the y, more to the bottom of the origin)\n",
    "        #                                 /\n",
    "        #                                /\n",
    "        #                               / z-axis\n",
    "        #                              /\n",
    "        #                             /_____________ x-axis (640)\n",
    "        #                             |\n",
    "        #                             |\n",
    "        #                             | y-axis (480)\n",
    "        #                             |\n",
    "        #                             |\n",
    "\n",
    "        # We now need to transform this to pyrobot frame, where\n",
    "        # x is into the camera, y is positive to the left,\n",
    "        # z is positive upwards\n",
    "        # https://pyrobot.org/docs/navigation\n",
    "        #                            |    /\n",
    "        #                 z-axis     |   /\n",
    "        #                            |  / x-axis\n",
    "        #                            | /\n",
    "        #  y-axis        ____________|/\n",
    "        #\n",
    "        # If you hold the first configuration in your right hand, and\n",
    "        # visualize the transformations needed to get to the second\n",
    "        # configuration, you'll see that\n",
    "        # you have to rotate 90 degrees anti-clockwise around the y axis, and then\n",
    "        # 90 degrees clockwise around the x axis.\n",
    "        # This results in the final configuration\n",
    "        roty90 = rotation_matrix_y(90)\n",
    "        rotxn90 = rotation_matrix_x(-90)\n",
    "        # next, rotate and translate pts by\n",
    "        # the robot pose and location\n",
    "        rot_base = rotation_matrix_z(math.degrees(base_state[2]))\n",
    "\n",
    "        rotation_matrix = rot_base @ rot_cam @ rotxn90 @ roty90  \n",
    "        translation_vector = np.array(\n",
    "            [trans_cam[0] + base_state[0], trans_cam[1] + base_state[1], trans_cam[2] + 0]\n",
    "        ).reshape(-1)\n",
    "\n",
    "        pts = np.dot(pts, rotation_matrix.T)\n",
    "        pts = pts + translation_vector\n",
    "\n",
    "        # now rewrite the ordering of pts so that the colors (rgb_rotated)\n",
    "        # match the indices of pts\n",
    "        # pts = pts.reshape((rgb.shape[0], rgb.shape[1], 3))\n",
    "        # pts = np.rot90(pts, k=1, axes=(1, 0))\n",
    "        # pts = pts.reshape(rgb.shape[0] * rgb.shape[1], 3)\n",
    "\n",
    "        # depth_rotated = np.rot90(depth_copy, k=1, axes=(1, 0))\n",
    "        # rgb_rotated = np.rot90(rgb, k=1, axes=(1, 0))\n",
    "\n",
    "        # return RGBDepth(rgb_rotated, depth_rotated, pts)\n",
    "        return pts\n",
    "\n",
    "def convert_depth_to_pcd(depth, pose, uv_one_in_cam, rot, trans):\n",
    "    # point cloud in camera frame\n",
    "    depth = (depth.astype(np.float32) / 1000.0).reshape(-1)\n",
    "    pts_in_cam = np.multiply(uv_one_in_cam, depth)\n",
    "    pts_in_cam = np.concatenate((pts_in_cam, np.ones((1, pts_in_cam.shape[1]))), axis=0)\n",
    "    # point cloud in robot base frame\n",
    "    pts_in_base = pts_in_cam[:3, :].T\n",
    "    pts_in_base = np.dot(pts_in_base, rot.T)\n",
    "    pts_in_base = pts_in_base + trans.reshape(-1)\n",
    "    # point cloud in world frame (pyrobot)\n",
    "    pts_in_world = transform_pose(pts_in_base, pose)\n",
    "    return pts_in_world\n",
    "\n",
    "# @njit\n",
    "def get_annot(height, width, pts_in_cur_img, src_pts_in_cur_cam, cur_pts_in_cur_cam, src_label, valid_z):\n",
    "    \"\"\"\n",
    "    This creates the new semantic labels of the projected points in the current image frame. Each new semantic label is the \n",
    "    semantic label corresponding to pts_in_cur_img in src_label. \n",
    "    \"\"\"\n",
    "    annot_img = np.zeros((height, width)).astype(np.float32)\n",
    "    print(f'annot_img.shape {annot_img.shape}, src_label.shape {src_label.shape}')\n",
    "    print(f'pts_in_cur_img.shape {pts_in_cur_img.shape}')\n",
    "    for indx in range(len(pts_in_cur_img)):\n",
    "        r = int(indx/width)\n",
    "        c = int(indx - r*width)\n",
    "        x, y, _ = pts_in_cur_img[indx]\n",
    "        # We take ceil and floor combinations to fix quantization errors\n",
    "        if not isnan(x) and not isnan(y) and (\n",
    "            floor(x) >= 0 and ceil(x) < width and floor(y) >=0 and ceil(y) < height\n",
    "        ):# and valid_z[indx]:\n",
    "            cur_indx = ceil(x) + ceil(y) * width\n",
    "            try:\n",
    "                # if src_pts_in_cur_cam[indx][2] - cur_pts_in_cur_cam[cur_indx][2] < 0.1:\n",
    "                annot_img[ceil(y)][ceil(x)] = src_label[r][c]\n",
    "                annot_img[floor(y)][floor(x)] = src_label[r][c]\n",
    "                annot_img[ceil(y)][floor(x)] = src_label[r][c]\n",
    "                annot_img[floor(y)][ceil(x)] = src_label[r][c]\n",
    "            except Exception as ex:\n",
    "                print(f'caught exception {ex}')\n",
    "                print(f'r c x y {r, c, x, y}')\n",
    "                raise ex\n",
    "    return annot_img\n",
    "    def closest_non_zero(a, x, y):\n",
    "        h, w = len(a), len(a[0])\n",
    "        def get_neighbors(a, curx, cury):\n",
    "            ns = []\n",
    "            if curx > 0:\n",
    "                ns.append((curx-1, cury)) # n\n",
    "            if cury > 0:\n",
    "                ns.append((curx, cury-1)) # w\n",
    "            if cury < w-1:\n",
    "                ns.append((curx, cury+1)) # e \n",
    "            if curx < h-1:\n",
    "                ns.append((curx+1, cury)) # s\n",
    "            if curx > 0 and cury > 0:\n",
    "                ns.append((curx-1, cury-1)) #nw\n",
    "            if curx > 0 and cury < w-1:\n",
    "                ns.append((curx-1, cury+1)) #ne\n",
    "            if curx < h-1 and cury < w-1:\n",
    "                ns.append((curx+1, cury+1)) #se\n",
    "            if curx < h-1 and cury > 0:\n",
    "                ns.append((curx+1, cury-1)) #sw \n",
    "            return ns\n",
    "\n",
    "        bfsq = deque([])\n",
    "        visited = np.zeros_like(a)\n",
    "        bfsq.append((x,y))\n",
    "        pop_count = 0\n",
    "        push_count = 1\n",
    "        while len(bfsq) > 0:\n",
    "            curx, cury = bfsq.popleft()\n",
    "            pop_count += 1\n",
    "            # if pop_count % 100 == 0:\n",
    "                # print(f'pop_count {pop_count}')\n",
    "            visited[curx][cury] = 1\n",
    "            if a[curx][cury] > 0:\n",
    "                return a[curx][cury]\n",
    "            if push_count < 8:\n",
    "                ns = get_neighbors(a, curx, cury)\n",
    "                for n in ns:\n",
    "                    try:\n",
    "                        if visited[n] == 0:\n",
    "                            push_count += 1\n",
    "                            bfsq.append(n)\n",
    "                    except Exception as ex:\n",
    "                        print(f'exception {ex} for n {n}')\n",
    "                        raise ex\n",
    "        # print(f'no nearest neighbor found after {pop_count} lookups! ...')\n",
    "        return 0\n",
    "\n",
    "    def max_vote(annot_img, x, y):\n",
    "        kernel_size = 5\n",
    "        votes = defaultdict(int)\n",
    "        for i in range(x-kernel_size, x+kernel_size):\n",
    "            for j in range(y-kernel_size, y+kernel_size):\n",
    "                if i >=0 and i < 512 and j > 0 and j < 512:\n",
    "                    v = annot_img[i][j]\n",
    "                    votes[v] += 1\n",
    "        return max(votes, key=votes.get)\n",
    "    \n",
    "    import random\n",
    "    import time\n",
    "    \n",
    "    def do_nn_fill(annot_img):\n",
    "        print(f'doing nn fill ...')\n",
    "        start = time.time()\n",
    "        print(f'zeros {np.sum(annot_img == 0)}')\n",
    "        for x in range(len(annot_img)):\n",
    "            for y in range(len(annot_img[0])):\n",
    "                if annot_img[x][y] == 0:# and random.randint(1,2) == 1:\n",
    "                    annot_img[x][y] = closest_non_zero(annot_img, x, y)\n",
    "                    # annot_img[x][y] = max_vote(annot_img, x, y)\n",
    "        end = time.time()\n",
    "        print(f'took {end - start} seconds.')\n",
    "        return annot_img\n",
    "    \n",
    "    return do_nn_fill(annot_img)\n",
    "\n",
    "def vis_pcd(points, colors, base_state):\n",
    "    points, colors = points.reshape(-1, 3), colors.reshape(-1, 3)\n",
    "    colors = colors / 255.\n",
    "\n",
    "   \n",
    "    opcd = o3d.geometry.PointCloud()\n",
    "    opcd.points = o3d.utility.Vector3dVector(points)\n",
    "    opcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "#     opcd = opcd.voxel_down_sample(0.03)\n",
    "\n",
    "    points = np.asarray(opcd.points)\n",
    "    colors = np.asarray(opcd.colors)\n",
    "\n",
    "    o3dviz.put('pointcloud', opcd)\n",
    "    \n",
    "    x, y, yaw = base_state\n",
    "    o3dviz.add_robot(base_state, 1.41)\n",
    "\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "def visualize_pcd(rgb, xyz, base_state):\n",
    "    \n",
    "    print(f'visualize_pcd shape {xyz.shape}')\n",
    "    # Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\n",
    "    \n",
    "    colors = rgb.reshape(-1, 3)\n",
    "    colors = colors / 255.\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(xyz/1000.)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "#     o3d.visualization.draw_geometries( [pcd])\n",
    "    \n",
    "    \n",
    "    viewer = o3d.visualization.Visualizer()\n",
    "    viewer.create_window()\n",
    "    v = viewer.get_view_control()\n",
    "    opt = viewer.get_render_option()\n",
    "    opt.show_coordinate_frame = True\n",
    "  \n",
    "    \n",
    "    look_at = np.array([1, 0, 0])  # look at x positive\n",
    "    cam_pos = [-5, 0, 1]  # 5 cm behind origin\n",
    "    y_axis = np.array([0, 0, 1])  # y axis is z-inward\n",
    "    v.set_lookat(look_at) \n",
    "    v.set_up(y_axis)\n",
    "    v.\n",
    "    \n",
    "    # viewer.scene.camera.look_at(look_at, cam_pos, y_axis)\n",
    "    \n",
    "\n",
    "    # viewer.add_geometry(pcd)\n",
    "#     viewer\n",
    "\n",
    "    \n",
    "    \n",
    "#     print(f'visualize_pcd base_state {base_state}')\n",
    "    x, y, yaw = [0., 0., 0.] # base_state\n",
    "\n",
    "    robot_orientation = o3d.geometry.TriangleMesh.create_arrow(cylinder_radius=.05,\n",
    "                                                       cone_radius=.075,\n",
    "                                                       cylinder_height = .50,\n",
    "                                                       cone_height = .4,\n",
    "                                                       resolution=20)\n",
    "    robot_orientation.compute_vertex_normals()\n",
    "    robot_orientation.paint_uniform_color([1.0, 0.5, 0.1])\n",
    "\n",
    "    robot_orientation.translate([x, y, 0.], relative=False)\n",
    "    # make the cylinder representing the robot to be parallel to the floor\n",
    "    robot_orientation.rotate(o3d.geometry.get_rotation_matrix_from_axis_angle([0, math.pi/2, 0]))\n",
    "    # rotate the cylinder by the robot orientation\n",
    "    if yaw != 0:\n",
    "        robot_orientation.rotate(o3d.geometry.get_rotation_matrix_from_axis_angle([0, 0, yaw]))\n",
    "\n",
    "    viewer.add_geometry(robot_orientation)\n",
    "    # viewer.add_geometry(pcd)\n",
    "    \n",
    "    viewer.run()\n",
    "    viewer.destroy_window()\n",
    "\n",
    "    \n",
    "#     o3d.io.write_point_cloud(\"TestData/sync.ply\", pcd)\n",
    "\n",
    "#     # Load saved point cloud and visualize it\n",
    "#     pcd_load = o3d.io.read_point_cloud(\"TestData/sync.ply\")\n",
    "#     o3d.visualization.draw_geometries([pcd_load])\n",
    "\n",
    "#     # convert Open3D.o3d.geometry.PointCloud to numpy array\n",
    "#     xyz_load = np.asarray(pcd_load.points)\n",
    "#     print('xyz_load')\n",
    "#     print(xyz_load)\n",
    "\n",
    "#     # save z_norm as an image (change [0,1] range to [0,255] range with uint8 type)\n",
    "#     img = o3d.geometry.Image((z_norm * 255).astype(np.uint8))\n",
    "#     o3d.io.write_image(\"TestData/sync.png\", img)\n",
    "#     o3d.visualization.draw_geometries([img])\n",
    "\n",
    "class LabelPropagate:\n",
    "    def __call__(self,    \n",
    "        src_img,\n",
    "        src_depth,\n",
    "        src_label,\n",
    "        src_pose,\n",
    "        cur_pose,\n",
    "        cur_depth,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        1. Gets point cloud for the source image \n",
    "        2. Transpose the point cloud based on robot location (cur_pose) \n",
    "        3. Project the point cloud back into the image frame. The corresponding semantic label for each point from the src_label becomes\n",
    "        the new semantic label in the current frame.\n",
    "        Args:\n",
    "            src_img (np.ndarray): source image to propagte from\n",
    "            src_depth (np.ndarray): source depth to propagte from\n",
    "            src_label (np.ndarray): source semantic map to propagte from\n",
    "            src_pose (np.ndarray): (x,y,theta) of the source image\n",
    "            cur_pose (np.ndarray): (x,y,theta) of current image\n",
    "            cur_depth (np.ndarray): current depth\n",
    "        \"\"\"\n",
    "        # Everything assumes image is still vertical\n",
    "\n",
    "        height, width, _ = src_img.shape\n",
    "        print(f'height {height} width {width}')\n",
    "        uv_one_in_cam, intrinsic_mat, rot, trans = compute_uvone(height, width) #640, 480)\n",
    "        print(f'uv_one_in_cam.shape {uv_one_in_cam.shape}')\n",
    "\n",
    "        src_pts_in_world = compute_pcd(src_img, src_depth, rot, trans, src_pose, uv_one_in_cam)\n",
    "        \n",
    "        #looks right\n",
    "        \n",
    "#         src_pts_in_world = src_pcd.reshape(height*width, 3) #\n",
    "#         src_pts_in_world = convert_depth_to_pcd(src_depth, src_pose, uv_one_in_cam, rot, trans)\n",
    "        \n",
    "        # visualize using o3d\n",
    "        visualize_pcd(src_img, src_pts_in_world, src_pose)\n",
    "        # vis_pcd(src_pts_in_world, src_img, src_pose)\n",
    "        \n",
    "#         # convert pts_in_world to current base\n",
    "#         src_pts_in_cur_base = transform_pose(src_pts_in_world, (-cur_pose[0], -cur_pose[1], 0))\n",
    "#         src_pts_in_cur_base = transform_pose(src_pts_in_cur_base, (0.0, 0.0, -cur_pose[2]))\n",
    "            \n",
    "#         # conver point from current base to current camera frame\n",
    "#         src_pts_in_cur_cam = src_pts_in_cur_base - trans.reshape(-1)\n",
    "#         src_pts_in_cur_cam = np.dot(src_pts_in_cur_cam, rot)\n",
    "        \n",
    "#         # Get Valid Z\n",
    "        valid_z = None # src_pts_in_cur_cam[:,2] > 0\n",
    "        \n",
    "        # Filter based on current depth.\n",
    "        # cur_depth = (cur_depth.astype(np.float32) / 1000.0).reshape(-1)\n",
    "        # cur_pts_in_cur_cam = np.multiply(uv_one_in_cam, cur_depth).T \n",
    "        \n",
    "        # conver pts in current camera frame into 2D pix values\n",
    "#         src_pts_in_cur_img = np.matmul(intrinsic_mat, src_pts_in_cur_cam.T).T        \n",
    "#         src_pts_in_cur_img /= src_pts_in_cur_img[:, 2].reshape([-1, 1])\n",
    "\n",
    "#         rgbd = RGBDepth(src_img, cur_depth, src_pts_in_cur_cam)\n",
    "\n",
    "        \n",
    "        print(f'src_pts_in_cur_cam.shape {src_pts_in_world.shape}')\n",
    "        \n",
    "        src_pts_in_cur_img = uncompute_pcd(src_pts_in_world.reshape(src_img.shape), rot, trans, cur_pose, intrinsic_mat)\n",
    "        \n",
    "        return get_annot(height, width, src_pts_in_cur_img, None, None, src_label, valid_z)\n",
    "\n",
    "\n",
    "\n",
    "# Stage 5: Run label prop\n",
    "# Ensure reex_dir has all objects reexplored\n",
    "\n",
    "# reex_dir = '/home/locobotm/explore_data/default/0/reexplore/'\n",
    "# explore_dir = '/home/locobotm/explore_data/default/0/'\n",
    "\n",
    "# soumiths data\n",
    "reex_dir = '/home/locobotm/0512_data/reexplore_data_0512_3/'\n",
    "explore_dir = '/home/locobotm/home2_data/0'\n",
    "\n",
    "# load reex json\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from droidlet.perception.robot import LabelPropagate\n",
    "from PIL import Image\n",
    "\n",
    "def save_propagated_visual(cur_img, semantic2, save_dir, out_indx):\n",
    "    \n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    cur_img = np.rot90(cur_img, k=1, axes=(1, 0))\n",
    "    semantic2 = np.rot90(semantic2, k=1, axes=(1, 0))\n",
    "\n",
    "    arr = [cur_img]\n",
    "    # arr.append(semantic1[0].reshape(480, 640))\n",
    "    # arr.append(\n",
    "    for semantic_obs in [semantic2]:\n",
    "        print(f'type(semantic_obs) {semantic_obs.shape}')\n",
    "        semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n",
    "        semantic_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "        semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n",
    "        semantic_img = semantic_img.convert(\"RGBA\")\n",
    "        arr.append(semantic_img)\n",
    "\n",
    "    titles = ['uncompute_pcd', 'propagated']\n",
    "    plt.figure(figsize=(12 ,8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 2, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "#     plt.savefig(\"{}/{:05d}.jpg\".format(save_dir, out_indx))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "reex_json = os.path.join(reex_dir, 'reexplore_data.json')\n",
    "with open(reex_json, 'r') as f:\n",
    "    reex_data = json.load(f)\n",
    "\n",
    "lp = LabelPropagate()\n",
    "    \n",
    "for reex_id in ['4']: #reex_data.keys():\n",
    "    obj_dir = os.path.join(reex_dir, reex_id)\n",
    "    obj_data = reex_data[reex_id]\n",
    "    print(f'obj_dir {obj_dir}')\n",
    "    src_img_indx = obj_data['src_img_id']\n",
    "    # for each examine heuristic\n",
    "    \n",
    "    # load src_img_id rgb, label and pose\n",
    "    src_img = cv2.imread(os.path.join(explore_dir, \"rgb/{:05d}.jpg\".format(src_img_indx)))\n",
    "    src_depth = np.load(os.path.join(explore_dir, \"depth/{:05d}.npy\".format(src_img_indx)))\n",
    "    src_pcd = np.load(os.path.join(explore_dir, \"pcd/{:05d}.npy\".format(src_img_indx)))\n",
    "    src_label = np.load(os.path.join(explore_dir, \"seg/{:05d}.npy\".format(src_img_indx)))\n",
    "    \n",
    "    src_label = np.rot90(src_label, k=-1, axes=(1, 0))\n",
    "    src_depth = np.rot90(src_depth, k=-1, axes=(1, 0))\n",
    "    src_img = np.rot90(src_img, k=-1, axes=(1, 0))\n",
    "    \n",
    "    with open(os.path.join(explore_dir, 'data.json'), \"r\") as f:\n",
    "        base_pose_data = json.load(f)\n",
    "    src_pose = base_pose_data[\"{}\".format(src_img_indx)]\n",
    "    \n",
    "    # for each heuristic, for each image in rgb, propagate \n",
    "    for heu in ['c1pp']:\n",
    "        heu_dir = os.path.join(obj_dir, heu)\n",
    "        prop_dir = os.path.join(heu_dir, 'pred')\n",
    "        print(f'saving propagated frames to {prop_dir}')\n",
    "        os.makedirs(prop_dir, exist_ok=True)\n",
    "\n",
    "        num_samples = min(len(os.listdir(os.path.join(heu_dir, 'rgb'))), 18)\n",
    "        with open(os.path.join(heu_dir, 'data.json'), \"r\") as f:\n",
    "            cur_pose_data = json.load(f) \n",
    "\n",
    "        for p in range(0, num_samples, 10):\n",
    "            cur_pose = cur_pose_data[str(p)]\n",
    "            cur_depth = np.load(os.path.join(heu_dir, \"depth/{:05d}.npy\".format(p)))    \n",
    "            cur_img = cv2.imread(os.path.join(heu_dir, \"rgb/{:05d}.jpg\".format(p)))\n",
    "            \n",
    "            cur_depth = np.rot90(cur_depth, k=-1, axes=(1, 0))\n",
    "            cur_img = np.rot90(cur_img, k=-1, axes=(1, 0))\n",
    "            \n",
    "            annot_img = lp(src_img, src_depth, src_label, src_pose, cur_pose, cur_depth)\n",
    "#             annot_img = np.rot90(annot_img, k=1, axes=(1, 0))\n",
    "            \n",
    "            print(annot_img.shape, annot_img.dtype)\n",
    "            mask = np.zeros(annot_img.shape[:2], dtype=\"uint8\")\n",
    "            mask[annot_img != 0] = True\n",
    "            \n",
    "            cur_img = cv2.bitwise_or(cur_img, cur_img, mask=mask)\n",
    "\n",
    "            np.save(os.path.join(prop_dir, \"{:05d}.npy\".format(p)), annot_img.astype(np.uint32))\n",
    "            save_propagated_visual(cur_img, annot_img, os.path.join(prop_dir, 'lp_visuals'), p)\n",
    "            \n",
    "            break\n",
    "            \n",
    "         #FIXME: also save the gt label\n",
    "\n",
    "        \n",
    "# TODO: combine all label prop for all objects in range(0,18,2) pred folders\n",
    "# TODO: run coco and training on each pred folder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa11c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "921600/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee830ad4-fdf3-494e-8b6a-a3c328edb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "640*480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a1915-c668-4619-a7f1-75be09e3c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "?o3d.visualization.draw_geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548ca000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "\u001b[1;33m[Open3D WARNING] gui::Initialize() was not called\u001b[0;m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[1;31m[Open3D Error] (void open3d::visualization::gui::Application::VerifyIsInitialized()) /root/Open3D/cpp/open3d/visualization/gui/Application.cpp:340: gui::Initialize() must be called before creating a window or UI element.\n\u001b[0;m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mo3d\u001b[39;00m\n\u001b[1;32m      2\u001b[0m o3d\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mwebrtc_server\u001b[38;5;241m.\u001b[39mdisable_http_handshake()\n\u001b[0;32m----> 3\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mO3DVisualizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D Error] (void open3d::visualization::gui::Application::VerifyIsInitialized()) /root/Open3D/cpp/open3d/visualization/gui/Application.cpp:340: gui::Initialize() must be called before creating a window or UI element.\n\u001b[0;m"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "o3d.visualization.webrtc_server.disable_http_handshake()\n",
    "v = o3d.visualization.O3DVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89671f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0c4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b76d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace3269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
