{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4eeba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Collect Explore\n",
    "# Stage 2: Annotate and convert labelme annotations to seg\n",
    "# Stage 3: Find spawn location and target for reexplore (reexplore_data.json)\n",
    "# Stage 4: Run reexplore for all objects, one at a time \n",
    "# Stage 5: Run label prop\n",
    "# Stage 6: Run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a7b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Collect Explore to $HOME/explore_data\n",
    "\n",
    "# Stage 3: Find spawn location and target for reexplore (reexplore_data.json) in a separate out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a191c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-05-13 18:55:00,277 - default_behaviors - Seed chosen: 116819841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_dir /home/locobotm/0512_data/reexplore_data_0512_3/4\n",
      "saving propagated frames to /home/locobotm/0512_data/reexplore_data_0512_3/4/c1pp/pred\n",
      "height 480 width 640\n",
      "uv_one_in_cam.shape (3, 307200)\n",
      "rgbd.depth.shape (480, 640), pts.shape (480, 640, 3)\n",
      "pts_in_cam.shape from uncompute_pcd (3, 307200)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cur_pts_in_cur_cam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m cur_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrot90(cur_depth, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    140\u001b[0m cur_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrot90(cur_img, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 142\u001b[0m annot_img, upcd \u001b[38;5;241m=\u001b[39m \u001b[43mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_pose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_pose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m annot_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrot90(annot_img, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(annot_img\u001b[38;5;241m.\u001b[39mshape, annot_img\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/fairo2/droidlet/perception/robot/handlers/label_propagate.py:426\u001b[0m, in \u001b[0;36mLabelPropagate.__call__\u001b[0;34m(self, src_img, src_depth, src_label, src_pose, cur_pose, cur_depth)\u001b[0m\n\u001b[1;32m    413\u001b[0m uncompute_img \u001b[38;5;241m=\u001b[39m uncompute_pcd(rgbd, rot, trans, cur_pose, uv_one_in_cam)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# from PIL import Image\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt \u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# semantic_img = semantic_img.convert(\"RGBA\")\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# arr.append(semantic_img)\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_annot(height, width, uncompute_img, src_pts_in_cur_cam, \u001b[43mcur_pts_in_cur_cam\u001b[49m, src_label, valid_z), uncompute_img\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cur_pts_in_cur_cam' is not defined"
     ]
    }
   ],
   "source": [
    "# Stage 5: Run label prop\n",
    "# Ensure reex_dir has all objects reexplored\n",
    "\n",
    "# reex_dir = '/home/locobotm/explore_data/default/0/reexplore/'\n",
    "# explore_dir = '/home/locobotm/explore_data/default/0/'\n",
    "\n",
    "# soumiths data\n",
    "reex_dir = '/home/locobotm/0512_data/reexplore_data_0512_3/'\n",
    "explore_dir = '/home/locobotm/home2_data/0'\n",
    "\n",
    "# load reex json\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from droidlet.perception.robot import LabelPropagate\n",
    "from PIL import Image\n",
    "\n",
    "d3_40_colors_rgb: np.ndarray = np.array(\n",
    "    [\n",
    "        [31, 119, 180],\n",
    "        [174, 199, 232],\n",
    "        [255, 127, 14],\n",
    "        [255, 187, 120],\n",
    "        [44, 160, 44],\n",
    "        [152, 223, 138],\n",
    "        [214, 39, 40],\n",
    "        [255, 152, 150],\n",
    "        [148, 103, 189],\n",
    "        [197, 176, 213],\n",
    "        [140, 86, 75],\n",
    "        [196, 156, 148],\n",
    "        [227, 119, 194],\n",
    "        [247, 182, 210],\n",
    "        [127, 127, 127],\n",
    "        [199, 199, 199],\n",
    "        [188, 189, 34],\n",
    "        [219, 219, 141],\n",
    "        [23, 190, 207],\n",
    "        [158, 218, 229],\n",
    "        [57, 59, 121],\n",
    "        [82, 84, 163],\n",
    "        [107, 110, 207],\n",
    "        [156, 158, 222],\n",
    "        [99, 121, 57],\n",
    "        [140, 162, 82],\n",
    "        [181, 207, 107],\n",
    "        [206, 219, 156],\n",
    "        [140, 109, 49],\n",
    "        [189, 158, 57],\n",
    "        [231, 186, 82],\n",
    "        [231, 203, 148],\n",
    "        [132, 60, 57],\n",
    "        [173, 73, 74],\n",
    "        [214, 97, 107],\n",
    "        [231, 150, 156],\n",
    "        [123, 65, 115],\n",
    "        [165, 81, 148],\n",
    "        [206, 109, 189],\n",
    "        [222, 158, 214],\n",
    "    ],\n",
    "    dtype=np.uint8,\n",
    ") \n",
    "\n",
    "def save_propagated_visual(semantic1, semantic2, save_dir, out_indx):\n",
    "    \n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    arr = []\n",
    "    # arr.append(semantic1[0].reshape(480, 640))\n",
    "    # arr.append(\n",
    "    for semantic_obs in [semantic1.T[0].reshape(480,640), semantic2]:\n",
    "        print(f'type(semantic_obs) {semantic_obs.shape}')\n",
    "        \n",
    "        \n",
    "        semantic_img = Image.new(\"P\", (semantic_obs.shape[0], semantic_obs.shape[1]))\n",
    "        semantic_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "        semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n",
    "        semantic_img = semantic_img.convert(\"RGBA\")\n",
    "        arr.append(semantic_img)\n",
    "\n",
    "    titles = ['uncompute_pcd', 'propagated']\n",
    "    plt.figure(figsize=(12 ,8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 2, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.savefig(\"{}/{:05d}.jpg\".format(save_dir, out_indx))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "reex_json = os.path.join(reex_dir, 'reexplore_data.json')\n",
    "with open(reex_json, 'r') as f:\n",
    "    reex_data = json.load(f)\n",
    "\n",
    "lp = LabelPropagate()\n",
    "    \n",
    "for reex_id in ['4']: #reex_data.keys():\n",
    "    obj_dir = os.path.join(reex_dir, reex_id)\n",
    "    obj_data = reex_data[reex_id]\n",
    "    print(f'obj_dir {obj_dir}')\n",
    "    src_img_indx = obj_data['src_img_id']\n",
    "    # for each examine heuristic\n",
    "    \n",
    "    # load src_img_id rgb, label and pose\n",
    "    src_img = cv2.imread(os.path.join(explore_dir, \"rgb/{:05d}.jpg\".format(src_img_indx)))\n",
    "    src_depth = np.load(os.path.join(explore_dir, \"depth/{:05d}.npy\".format(src_img_indx)))\n",
    "    src_pcd = np.load(os.path.join(explore_dir, \"pcd/{:05d}.npy\".format(src_img_indx)))\n",
    "    src_label = np.load(os.path.join(explore_dir, \"seg/{:05d}.npy\".format(src_img_indx)))\n",
    "    \n",
    "    src_label = np.rot90(src_label, k=-1, axes=(1, 0))\n",
    "    src_depth = np.rot90(src_depth, k=-1, axes=(1, 0))\n",
    "    src_img = np.rot90(src_img, k=-1, axes=(1, 0))\n",
    "    \n",
    "    with open(os.path.join(explore_dir, 'data.json'), \"r\") as f:\n",
    "        base_pose_data = json.load(f)\n",
    "    src_pose = base_pose_data[\"{}\".format(src_img_indx)]\n",
    "    \n",
    "    # for each heuristic, for each image in rgb, propagate \n",
    "    for heu in ['c1pp']:\n",
    "        heu_dir = os.path.join(obj_dir, heu)\n",
    "        prop_dir = os.path.join(heu_dir, 'pred')\n",
    "        print(f'saving propagated frames to {prop_dir}')\n",
    "        os.makedirs(prop_dir, exist_ok=True)\n",
    "\n",
    "        num_samples = min(len(os.listdir(os.path.join(heu_dir, 'rgb'))), 18)\n",
    "        with open(os.path.join(heu_dir, 'data.json'), \"r\") as f:\n",
    "            cur_pose_data = json.load(f) \n",
    "\n",
    "        for p in range(num_samples):\n",
    "            cur_pose = cur_pose_data[str(p)]\n",
    "            cur_depth = np.load(os.path.join(heu_dir, \"depth/{:05d}.npy\".format(p)))    \n",
    "#             cur_depth = np.load(os.path.join(heu_dir, \"depth/{:05d}.npy\".format(p)))\n",
    "            cur_img = cv2.imread(os.path.join(heu_dir, \"rgb/{:05d}.jpg\".format(p)))\n",
    "            \n",
    "            cur_depth = np.rot90(cur_depth, k=-1, axes=(1, 0))\n",
    "            cur_img = np.rot90(cur_img, k=-1, axes=(1, 0))\n",
    "            \n",
    "            annot_img, upcd = lp(src_img, src_depth, src_label, src_pose, cur_pose, cur_depth)\n",
    "            annot_img = np.rot90(annot_img, k=1, axes=(1, 0))\n",
    "            \n",
    "            print(annot_img.shape, annot_img.dtype)\n",
    "            mask = np.zeros(annot_img.shape[:2], dtype=\"uint8\")\n",
    "            mask[annot_img != 0] = True\n",
    "            \n",
    "            # cur_img = cv2.bitwise_or(cur_img, cur_img, mask=mask)\n",
    "\n",
    "            np.save(os.path.join(prop_dir, \"{:05d}.npy\".format(p)), annot_img.astype(np.uint32))\n",
    "            save_propagated_visual(upcd, annot_img, os.path.join(prop_dir, 'lp_visuals'), p)\n",
    "            \n",
    "         #FIXME: also save the gt label\n",
    "\n",
    "        \n",
    "# TODO: combine all label prop for all objects in range(0,18,2) pred folders\n",
    "# TODO: run coco and training on each pred folder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa11c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "921600/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee830ad4-fdf3-494e-8b6a-a3c328edb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "640*480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a1915-c668-4619-a7f1-75be09e3c9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
